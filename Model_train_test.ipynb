{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpelm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Flatten,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.graph_objs import Layout, Figure, Marker\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "CNN_EPOCH =30\n",
    "image_shape=(224,224,3)\n",
    "NUM_CLASS = 2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload():\n",
    "    train_data=ImageDataGenerator(rescale=1/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,)\n",
    "    training_data= train_data.flow_from_directory(\"Dehazed_Images_3400/Dehazed_Images/train\",target_size=(224,224),class_mode='binary' )\n",
    "    training_data\n",
    "\n",
    "    test_data=ImageDataGenerator(rescale=1/255)\n",
    "    testing_data=test_data.flow_from_directory(\"Dehazed_Images_3400/Dehazed_Images/test\",target_size=(224,224),class_mode='binary')\n",
    "    return training_data,testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_generate(training_data,testing_data):\n",
    "   \n",
    "    np.random.seed(1000)\n",
    "    training_data_oh = np_utils.to_categorical(training_data.classes, NUM_CLASS)\n",
    "    model=Sequential()\n",
    "\n",
    "    #1\n",
    "    model.add(Conv2D(filters=96,input_shape=image_shape,kernel_size=(11,11),strides=(4,4),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "\n",
    "\n",
    "    #2\n",
    "    model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "\n",
    "    #3\n",
    "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #4\n",
    "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #5\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same', ))\n",
    "\n",
    "    model.add(Flatten())\n",
    " \n",
    "    #Ist fc layer \n",
    "    model.add(Dense(4096,input_shape=(224,224,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    lrr= ReduceLROnPlateau( monitor='val_accuracy',   factor=.01,   patience=3,  min_lr=1e-5) \n",
    "    \n",
    "  \n",
    "\n",
    "    t0=time.time()\n",
    "    history=model.fit(training_data,epochs=CNN_EPOCH,validation_data=testing_data,validation_steps=2,callbacks = [lrr])\n",
    "    print(\"Training time :\" , time.time()-t0)\n",
    "    #accuracy vs validation accuracy\n",
    "    p1=plt\n",
    "    p1.plot(history.history['accuracy'])\n",
    "    p1.plot(history.history['val_accuracy'])\n",
    "    p1.title('model accuracy')\n",
    "    p1.ylabel('accuracy')\n",
    "    p1.xlabel('epoch')\n",
    "    p1.legend(['train', 'test'], loc='upper left')\n",
    "    p1.show()\n",
    "\n",
    "\n",
    "    p2=plt\n",
    "    #training loss vs validation loss\n",
    "    p2.plot(history.history['loss'])\n",
    "    p2.plot(history.history['val_loss'])\n",
    "    p2.title('model loss')\n",
    "    p2.ylabel('loss')\n",
    "    p2.xlabel('epoch')\n",
    "    p2.legend(['train', 'test'], loc='upper left')\n",
    "    p2.show()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer_generate(cnn_model,training_data):\n",
    "    layer_name = 'flatten'\n",
    "    hidden_layer_model = Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(layer_name).output)\n",
    "\n",
    "    cnn_train_result = hidden_layer_model.predict(training_data)\n",
    "    #print(cnn_train_result)\n",
    "    return hidden_layer_model, cnn_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elm_model_generate(data_train, training_data):\n",
    "    NUM_CLASS=2\n",
    "    ELM_HIDDEN_NEURONS=256\n",
    "    target_train_oh = np_utils.to_categorical(training_data.classes, NUM_CLASS)\n",
    "    \n",
    "    elm_model = hpelm.elm.ELM(data_train.shape[1], NUM_CLASS)\n",
    "    elm_model.add_neurons(ELM_HIDDEN_NEURONS, func='sigm')\n",
    "    #print(data_train,target_train_oh)\n",
    "    elm_model.train(data_train, target_train_oh, 'c')\n",
    "    \n",
    "    return elm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_fscore(precision, recall, fscore, filename='new_result.html'):\n",
    "    print(\"precision=\",precision,\"recall=\",recall,\"fscore=\",fscore)\n",
    "    avg_data = np.array([\n",
    "        np.mean(precision),\n",
    "        np.mean(recall),\n",
    "        np.mean(fscore)\n",
    "    ])\n",
    "\n",
    "    panda_avg = pd.DataFrame(avg_data).round(3)\n",
    "\n",
    "    data = np.array(panda_avg.values).T[0]\n",
    "\n",
    "    print(avg_data)\n",
    "    print(panda_avg)\n",
    "    print(data)\n",
    "    \n",
    "    trace = [plotly.graph_objs.Bar(\n",
    "        x=['precision', 'recall', 'fscore'],\n",
    "        y=data,\n",
    "        marker=Marker(color='#04b486'),\n",
    "        text=data,\n",
    "        textposition='auto',\n",
    "        textfont=dict(color='black', size=20)\n",
    "    )]\n",
    "\n",
    "    layout = Layout(bargap=0.6, plot_bgcolor='#E6E6E6')\n",
    "    plot_data = Figure(data=trace, layout=layout)\n",
    "    plotly.offline.plot(plot_data, filename=filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9f79f829382866278eada64dff3ff002f65deb882a3977d3dc9813be743fb22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
