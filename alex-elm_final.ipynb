{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpelm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers.core import Dense, Activation, Flatten,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.graph_objs import Layout, Figure, Marker\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "CNN_EPOCH =30\n",
    "image_shape=(224,224,3)\n",
    "NUM_CLASS = 2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload():\n",
    "    train_data=ImageDataGenerator(rescale=1/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,)\n",
    "    training_data= train_data.flow_from_directory(\"Dehazed_Images_3400/Dehazed_Images/train\",target_size=(224,224),class_mode='binary' )\n",
    "    training_data\n",
    "\n",
    "    test_data=ImageDataGenerator(rescale=1/255)\n",
    "    testing_data=test_data.flow_from_directory(\"Dehazed_Images_3400/Dehazed_Images/test\",target_size=(224,224),class_mode='binary')\n",
    "    return training_data,testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_generate(training_data,testing_data):\n",
    "   \n",
    "    np.random.seed(1000)\n",
    "    training_data_oh = np_utils.to_categorical(training_data.classes, NUM_CLASS)\n",
    "    model=Sequential()\n",
    "\n",
    "    #1\n",
    "    model.add(Conv2D(filters=96,input_shape=image_shape,kernel_size=(11,11),strides=(4,4),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "\n",
    "\n",
    "    #2\n",
    "    model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "\n",
    "    #3\n",
    "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #4\n",
    "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    #5\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same', ))\n",
    "\n",
    "    model.add(Flatten())\n",
    " \n",
    "    #Ist fc layer \n",
    "    model.add(Dense(4096,input_shape=(224,224,3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(1))    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    lrr= ReduceLROnPlateau( monitor='val_accuracy',   factor=.01,   patience=3,  min_lr=1e-5) \n",
    "    \n",
    "  \n",
    "\n",
    "    t0=time.time()\n",
    "    history=model.fit(training_data,epochs=CNN_EPOCH,validation_data=testing_data,validation_steps=2,callbacks = [lrr])\n",
    "    print(\"Training time :\" , time.time()-t0)\n",
    "    #accuracy vs validation accuracy\n",
    "    p1=plt\n",
    "    p1.plot(history.history['accuracy'])\n",
    "    p1.plot(history.history['val_accuracy'])\n",
    "    p1.title('model accuracy')\n",
    "    p1.ylabel('accuracy')\n",
    "    p1.xlabel('epoch')\n",
    "    p1.legend(['train', 'test'], loc='upper left')\n",
    "    p1.show()\n",
    "\n",
    "\n",
    "    p2=plt\n",
    "    #training loss vs validation loss\n",
    "    p2.plot(history.history['loss'])\n",
    "    p2.plot(history.history['val_loss'])\n",
    "    p2.title('model loss')\n",
    "    p2.ylabel('loss')\n",
    "    p2.xlabel('epoch')\n",
    "    p2.legend(['train', 'test'], loc='upper left')\n",
    "    p2.show()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer_generate(cnn_model,training_data):\n",
    "    layer_name = 'flatten'\n",
    "    hidden_layer_model = Model(inputs=cnn_model.input, outputs=cnn_model.get_layer(layer_name).output)\n",
    "\n",
    "    cnn_train_result = hidden_layer_model.predict(training_data)\n",
    "    #print(cnn_train_result)\n",
    "    return hidden_layer_model, cnn_train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elm_model_generate(data_train, training_data):\n",
    "    NUM_CLASS=2\n",
    "    ELM_HIDDEN_NEURONS=256\n",
    "    target_train_oh = np_utils.to_categorical(training_data.classes, NUM_CLASS)\n",
    "    \n",
    "    elm_model = hpelm.elm.ELM(data_train.shape[1], NUM_CLASS)\n",
    "    elm_model.add_neurons(ELM_HIDDEN_NEURONS, func='sigm')\n",
    "    #print(data_train,target_train_oh)\n",
    "    elm_model.train(data_train, target_train_oh, 'c')\n",
    "    \n",
    "    return elm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "def cnn_elm_evaluation(cnn_part, elm_part, data_test, testing_data, file_name=\"plot_result.html\"):\n",
    "\n",
    "    \"\"\"\n",
    "    :param cnn_part: CNN Model\n",
    "    :param elm_part: ELM Model\n",
    "    :return: Result Score\n",
    "    \"\"\"\n",
    "\n",
    "    target_test_oh = np_utils.to_categorical(testing_data.classes, NUM_CLASS)\n",
    "\n",
    "    cnn_result = cnn_part.predict(data_test)\n",
    "    elm_result = elm_part.predict(cnn_result)\n",
    "\n",
    "    elm_result_class = np.array([np.argmax(r) for r in elm_result])\n",
    "    #print(elm_result_class)\n",
    "    \n",
    "    confusion = elm_part.confusion(target_test_oh, elm_result)\n",
    "    print(confusion)\n",
    "\n",
    "    accuracy = (confusion[0][0]+confusion[1][1])/(confusion[0][0]+confusion[0][1]+confusion[1][0]+confusion[1][1])\n",
    "   \n",
    "    \n",
    "    Sensitivity = confusion[0][0]/(confusion[0][0]+confusion[1][1])\n",
    "    Specificity =confusion[1][1]/(confusion[0][1]+confusion[1][1])\n",
    "    fpr = 1-Specificity\n",
    "    #cm_display=metrics.ConfusionMatrixDisplay(confusion,display_labels=[False,True])\n",
    "    #cm_display.plot()\n",
    "    print(\"accuracy =\" ,accuracy)\n",
    "    print(\"Sensitivity=\",Sensitivity)\n",
    "    print(\"Specificity=\" ,Specificity)\n",
    "    print(\"fpr=\",fpr)\n",
    "    \n",
    "    error=elm_part.error(target_test_oh,elm_result)\n",
    "    print(\"error=\",error)\n",
    "\n",
    "    \n",
    "    # Confusion Matrix Plot\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                confusion.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                        confusion.flatten()/np.sum(confusion)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "            zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(confusion, annot=labels, fmt='',xticklabels=['busy','free'],yticklabels=['busy','free'],)\n",
    "\n",
    "    \n",
    "    \n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(testing_data.classes, elm_result_class)\n",
    "    \n",
    "    print(precision, recall, fscore, support)\n",
    "\n",
    "    return precision, recall, fscore, support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_fscore(precision, recall, fscore, filename='new_result.html'):\n",
    "    print(\"precision=\",precision,\"recall=\",recall,\"fscore=\",fscore)\n",
    "    avg_data = np.array([\n",
    "        np.mean(precision),\n",
    "        np.mean(recall),\n",
    "        np.mean(fscore)\n",
    "    ])\n",
    "\n",
    "    panda_avg = pd.DataFrame(avg_data).round(3)\n",
    "\n",
    "    data = np.array(panda_avg.values).T[0]\n",
    "\n",
    "    print(avg_data)\n",
    "    print(panda_avg)\n",
    "    print(data)\n",
    "    \n",
    "    trace = [plotly.graph_objs.Bar(\n",
    "        x=['precision', 'recall', 'fscore'],\n",
    "        y=data,\n",
    "        marker=Marker(color='#04b486'),\n",
    "        text=data,\n",
    "        textposition='auto',\n",
    "        textfont=dict(color='black', size=20)\n",
    "    )]\n",
    "\n",
    "    layout = Layout(bargap=0.6, plot_bgcolor='#E6E6E6')\n",
    "    plot_data = Figure(data=trace, layout=layout)\n",
    "    plotly.offline.plot(plot_data, filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    training_data,testing_data=dataload()\n",
    "    t1=time.time()    \n",
    "    model=cnn_generate(training_data,testing_data)\n",
    "    hidden_layer_model, cnn_train_result = hidden_layer_generate(model,training_data)\n",
    "   \n",
    "    elm_model = elm_model_generate(cnn_train_result, training_data)\n",
    "\n",
    "    precision, recall, fscore, support = cnn_elm_evaluation(hidden_layer_model, elm_model, testing_data, testing_data)\n",
    "\n",
    "    plot_precision_recall_fscore(precision, recall, fscore)\n",
    "    print(\"total time\",time.time()-t1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   \n",
    "elm_model = elm_model_generate(cnn_train_result, training_data)\n",
    "\n",
    "precision, recall, fscore, support = cnn_elm_evaluation(hidden_layer_model, elm_model, testing_data, testing_data)\n",
    "\n",
    "plot_precision_recall_fscore(precision, recall, fscore)\n",
    "print(\"total time\",time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "classifiers = ['Classifier1', 'Classifier2']\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "folds = ['Fold1', 'Fold2', 'Fold3', 'Fold4', 'Fold5']\n",
    "\n",
    "# Sample performance metrics (replace with your actual metrics)\n",
    "data = {\n",
    "    ('Classifier1', 'Accuracy'): [0.85, 0.82, 0.87, 0.78, 0.84],\n",
    "    ('Classifier1', 'Precision'): [0.80, 0.77, 0.82, 0.75, 0.79],\n",
    "    ('Classifier1', 'Recall'): [0.75, 0.72, 0.77, 0.70, 0.75],\n",
    "    ('Classifier1', 'F1-score'): [0.78, 0.75, 0.80, 0.73, 0.78],\n",
    "    ('Classifier2', 'Accuracy'): [0.80, 0.78, 0.82, 0.75, 0.79],\n",
    "    ('Classifier2', 'Precision'): [0.78, 0.75, 0.79, 0.72, 0.78],\n",
    "    ('Classifier2', 'Recall'): [0.72, 0.70, 0.74, 0.67, 0.72],\n",
    "    ('Classifier2', 'F1-score'): [0.75, 0.73, 0.77, 0.70, 0.75],\n",
    "    # Add data for other classifiers...\n",
    "}\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate mean performance metrics across folds\n",
    "mean_performance = df.mean(axis=1, level=1)\n",
    "\n",
    "# Plot line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for classifier in classifiers:\n",
    "    for metric in metrics:\n",
    "        plt.plot(folds, mean_performance[classifier][metric], label=f\"{classifier} - {metric}\")\n",
    "\n",
    "plt.title('Mean Performance Metrics Across Folds')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Mean Performance Metric')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9f79f829382866278eada64dff3ff002f65deb882a3977d3dc9813be743fb22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
